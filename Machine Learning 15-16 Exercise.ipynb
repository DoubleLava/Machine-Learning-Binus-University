{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc6725d-db4e-4e86-8784-df4111998476",
   "metadata": {},
   "source": [
    "# Session 15-16 Decision Tree and Ensemble Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce6c410e-1a77-400c-902e-7f320aef07a2",
   "metadata": {},
   "source": [
    "# Exercise: Titanic Survival Prediction\n",
    "\n",
    "You are a data scientist tasked with analyzing the Titanic dataset\n",
    "\n",
    "https://www.kaggle.com/competitions/titanic\n",
    "\n",
    "The goal of this exercise is to build and compare classification models that predict whether a passenger survived the Titanic disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ff5ba-aeb6-43db-b356-aace6c81d704",
   "metadata": {},
   "source": [
    "# Step 1. Data Preparation\n",
    "\n",
    "## Goal: Load data, select features, handle missing values, encode categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb789550-a205-40d9-8e3e-7a11b6785ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preparation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791a2233-0662-4f50-8e62-7ddfde8fa46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Inspect dataset\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdacbf4-dd2c-4c55-8d7c-b45527a97273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "y = data[\"Survived\"]\n",
    "\n",
    "# Select relevant features\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"Fare\", \"SibSp\", \"Parch\"]\n",
    "X = data[features].copy()  # use copy to avoid SettingWithCopyWarning\n",
    "\n",
    "# Handle missing values\n",
    "X[\"Age\"] = X[\"Age\"].fillna(X[\"Age\"].median())\n",
    "\n",
    "# Encode categorical variable\n",
    "# male -> 0, female -> 1\n",
    "X[\"Sex\"] = X[\"Sex\"].map({\"male\": 0, \"female\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f446665-7d68-4097-bfbd-d1677570f396",
   "metadata": {},
   "source": [
    "# Step 2. Trainâ€“Test Split\n",
    "\n",
    "## Goal: Split data into 70% training and 30% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b028ae-c1da-41e9-895c-b295f48eb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train-Test Split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a966e567-d7a0-421c-88d4-3c2a7a75b639",
   "metadata": {},
   "source": [
    "# Step 3. Model Development\n",
    "\n",
    "## Goal: Train Decision Tree, Random Forest, and AdaBoost using the same feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2511e09-1dd7-42a3-9042-7be68441bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Model Development\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train all models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6a986-6634-490d-be80-d0940b303717",
   "metadata": {},
   "source": [
    "# Step 4. Model Evaluation\n",
    "\n",
    "## Goal: Evaluate each model using Accuracy, Precision, Recall, ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6801c-afcc-425d-aae4-65f10104f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Model Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Metrics\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_pred_proba)\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96ee02-89b2-4228-a7c8-bf655c92fb88",
   "metadata": {},
   "source": [
    "## Drawing ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65864445-b430-4adf-9464-6d1db9b19644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1): Import required functions\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (2): Compute False Positive Rate (FPR) and True Positive Rate (TPR)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# (3): Compute Area Under the Curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# (4): Plot ROC curve\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.3f})\")\n",
    "\n",
    "# Diagonal line = random classifier\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", label=\"Random classifier\")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - SVM Titanic Survival Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b33a12-ffc7-4768-89e8-61fe6f72eef3",
   "metadata": {},
   "source": [
    "# Step 5. Confusion Matrix Analysis\n",
    "\n",
    "## Goal: Compute and interpret TP, FP, TN, FN for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726fe1f2-2c47-48ed-9221-450c9c6ecdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Confusion Matrix Analysis\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    \n",
    "    print(f\"\\n{name} Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"TP:\", TP, \"- Correctly predicted survivors\")\n",
    "    print(\"FP:\", FP, \"- Predicted survived but did not\")\n",
    "    print(\"TN:\", TN, \"- Correctly predicted non-survivors\")\n",
    "    print(\"FN:\", FN, \"- Predicted non-survivor but survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07424d09-4f8b-4acd-b5ff-72a46b80bee4",
   "metadata": {},
   "source": [
    "# Step 6. Model Comparison\n",
    "\n",
    "## Goal: Compare models and discuss which performs best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d075d3-5a76-4499-be32-ab6acf376880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Model Comparison\n",
    "\n",
    "comparison_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison Table:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3ffb8-e23e-4865-b993-0054460deb40",
   "metadata": {},
   "source": [
    "### Discussion:\n",
    "- Decision Tree is simple but prone to overfitting.\n",
    "- Random Forest reduces variance by averaging many trees.\n",
    "- AdaBoost focuses on hard-to-classify samples.\n",
    "- Typically, Random Forest or AdaBoost achieves the best ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df7776-21ad-459f-8334-260aacfb2fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
